---
title: "houseing-affordability-R"
output: html_notebook
---

# Introduction

This notebook documents the **data ingestion stage** of the housing affordability analysis pipeline. Its purpose is to retrieve, validate, and store raw data from multiple public sources in a consistent and reproducible manner. All subsequent transformation, analysis, and modeling steps depend on the integrity of the data collected here.

The ingestion process integrates data from three primary sources. Zillow Home Value Index (ZHVI) data provide monthly measures of median home values by metropolitan area. Macroeconomic indicators, including mortgage interest rates and inflation, are sourced from the Federal Reserve Economic Data (FRED) API. Median household income data are obtained from the U.S. Census Bureauâ€™s American Community Survey (ACS). Together, these datasets form the foundation for constructing a longitudinal panel of housing market conditions across U.S. metropolitan areas.

This notebook focuses exclusively on **data acquisition and initial validation**. It performs no feature engineering or analytical transformations beyond those required to standardize variable names, date formats, and geographic identifiers. Each ingestion step includes basic verification checks to confirm data completeness and expected ranges before writing outputs to disk.

All raw data generated by this notebook are saved to the `data/raw/` directory and are intentionally excluded from version control. Reproducibility is ensured through the use of API-based retrieval, environment-managed dependencies, and explicit documentation of data sources and parameters. Downstream notebooks rely on these raw files as immutable inputs for transformation and analysis.

```{r}
library(tidyverse)
library(lubridate)
library(broom)
library(corrplot)
library(fredr)

```

```{r}
set.seed(42)
```

------------------------------------------------------------------------

## Data Ingestion

```{r}
library(tidycensus)
census_api_key(Sys.getenv("CENSUS_API_KEY"))


```

```{r}
library(fredr)
fredr_set_key(Sys.getenv("FRED_API_KEY"))

```

```{r}
# --- Helper: pull a FRED series into a tidy tibble ---
get_fred_series <- function(series_id, start_date = as.Date("2000-01-01")) {
  fredr::fredr(
    series_id = series_id,
    observation_start = start_date
  ) %>%
    select(date, value) %>%
    rename(!!series_id := value)
}

# --- Choose series to ingest ---
# Commonly useful for housing affordability:
series_ids <- c(
  "MORTGAGE30US",  # 30-year fixed mortgage rate (weekly)
  "CSUSHPISA",     # Case-Shiller US HPI (monthly)
  "CPIAUCSL"       # CPI (monthly)
)

start_date <- as.Date("2000-01-01")

verify_fred_df <- function(df) {
  #basic ingestion checks
  stopifnot("date" %in% names(df))
  stopifnot(nrow(df) > 0)
  stopifnot(is.Date(df$date))
  
  value_col <- setdiff(names(df), "date")
  stopifnot(length(value_col) == 1)
  
  tibble(
    series_id   = value_col,
    n_rows      = nrow(df),
    start_date  = min(df$date, na.rm = TRUE),
    end_date    = max(df$date, na.rm = TRUE),
    n_missing   = sum(is.na(df[[value_col]])),
    n_dup_dates = sum(duplicated(df$date))
  )
}

ingestion_report <- map_dfr(series_ids, function(sid){
  df <- get_fred_series(sid,start_date = start_date)
  
  #verification summary
  report <- verify_fred_df(df)
  
  #quick peek (optional)
  message("\n--",sid," ---")
  print(head(df,3))
  print(tail(df,3))
  print(report)
  out_path <- file.path("./data/raw", paste0("fred_", sid,"_",format(start_date, "%Y%m%d"),".csv"))
  write_csv(df, out_path)
  report %>% mutate(saved_to = out_path)
})
```

```{r}

ingestion_report

```

#### Census Data Ingestion

```{r}
# --- Helper: ACS median household income (B19013) by Metro (CBSA) ---
get_acs_median_hh_income_metro <- function(year = 2023) {
  df <- get_acs(
    geography = "metropolitan statistical area/micropolitan statistical area",
    table = "B19013",
    year = year,
    survey = "acs5",
    cache_table = TRUE
  ) %>%
    transmute(
      year = year,
      geo_id = GEOID,
      region = NAME,
      income_median_hh = estimate,
      moe = moe
    )

  df
}

#---Pull data ---
YEAR <- 2023
income_metro <- get_acs_median_hh_income_metro(year = YEAR)

#---Verification---
stopifnot(nrow(income_metro) > 0)
stopifnot(all(c("geo_id","region","income_median_hh") %in% names(income_metro)))

verification <- income_metro %>%
  summarise(
    year   = first(year),
    n_rows = n(),
    n_missing_income = sum(is.na(income_median_hh)),
    min_income = min(income_median_hh, na.rm = TRUE),
    max_income = max(income_median_hh, na.rm = TRUE)
  )

print(head(income_metro, 5))
print(verification)

#---Save to raw---
out_path <- file.path("./data/raw",paste0("ac5_median_hh_income_metro_",YEAR,".csv"))
write_csv(income_metro, out_path)

message("Saved:", out_path)

```

## Updated ingestion (multi-year ACS5 income by metro)

```{r}
library(tidyverse)
library(tidycensus)
library(readr)

# --- Helper: ACS median household income (B19013) by Metro (CBSA), multi-year ---
get_acs_median_hh_income_metro <- function(years = 2009:2023) {
  stopifnot(length(years) > 0)

  df <- purrr::map_dfr(years, function(y) {
    get_acs(
      geography = "metropolitan statistical area/micropolitan statistical area",
      table = "B19013",
      year = y,
      survey = "acs5",
      cache_table = TRUE
    ) %>%
      transmute(
        year = y,
        geo_id = GEOID,
        region = NAME,
        income_median_hh = estimate,
        moe = moe
      )
  })

  df
}

# --- Pull data ---
YEARS <- 2009:2023
income_metro <- get_acs_median_hh_income_metro(years = YEARS)

# --- Verification ---
stopifnot(nrow(income_metro) > 0)
stopifnot(all(c("year", "geo_id", "region", "income_median_hh") %in% names(income_metro)))

verification <- income_metro %>%
  summarise(
    year_min = min(year),
    year_max = max(year),
    n_rows = n(),
    n_regions = n_distinct(region),
    n_missing_income = sum(is.na(income_median_hh)),
    min_income = min(income_median_hh, na.rm = TRUE),
    max_income = max(income_median_hh, na.rm = TRUE)
  )

print(head(income_metro, 5))
print(verification)

# Optional: verify coverage by year
coverage_by_year <- income_metro %>%
  group_by(year) %>%
  summarise(
    n_regions = n_distinct(region),
    pct_missing_income = mean(is.na(income_median_hh)),
    .groups = "drop"
  )

print(head(coverage_by_year, 10))

# --- Save to raw ---
dir.create("data/raw", recursive = TRUE, showWarnings = FALSE)

out_path <- file.path(
  "data/raw",
  paste0("acs5_median_hh_income_metro_", min(YEARS), "_", max(YEARS), ".csv")
)

write_csv(income_metro, out_path)
message("Saved: ", out_path)

```
